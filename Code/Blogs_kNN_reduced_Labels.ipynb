{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textklassifikation mit Bag-of-Words-Vektorisierung in tf-idf-Repräsentation und kNN-Algorithmus \n",
    "Labels (Themen und Disziplinen) sind auf höchste Hierarchieebene reduziert\n",
    "\n",
    "Autorin: Maria Hartmann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer # module to one-hot-encode the labels\n",
    "from sklearn.pipeline import Pipeline # assemples transormers \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer # module to transform a count matrix to a normalized tf-idf representation\n",
    "from sklearn.neighbors import KNeighborsClassifier # k-nearest neighbors classifier (supports multi-label classification)\n",
    "from sklearn.model_selection import RandomizedSearchCV # module for paramter optimization\n",
    "\n",
    "np.random.seed(7) # fix random seed for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einlesen des Trainings- und Testdatensatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = '../Datasets/reduced_labels_trainset.csv' \n",
    "testset = '../Datasets/reduced_labels_testset.csv' \n",
    "\n",
    "trainset_csv = pd.read_csv(trainset, delimiter=';')\n",
    "X_train = trainset_csv['text'].values\n",
    "y_train = trainset_csv['classes'].values\n",
    "z_train = trainset_csv['filename'].values\n",
    "\n",
    "testset_csv = pd.read_csv(testset, delimiter=';')\n",
    "X_test = testset_csv['text'].values\n",
    "y_test = testset_csv['classes'].values\n",
    "z_test = testset_csv['filename'].values\n",
    "\n",
    "# Splitten der Labels pro Blogbeitrag\n",
    "y_train = [e.split(', ') for e in y_train]\n",
    "y_test = [e.split(', ') for e in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "archivalia_575.txt\n",
      "['pluridisciplinarité_d', 'épistémologie et méthodes_t', 'histoire_t', 'histoire et archéologie_d']\n",
      "diese titelformulierung der hab in ihrer handschriftendatenbank ist besonders sinnreich http diglib hab de db mss list ms id aug f mit digitalisat ich möchte nicht wissen wieviele forscher sich auf die fehlanzeige des verlinkten opacs der grundsätzlich nichts zu den handschriften ausspuckt während die ältere dokumentation funktioniert verlassen und so unnötig rechercheaufwand betreiben müssen kürzt man die signatur findet man den hinweis auf die münchner schedel ausstellung welt des wissens bevor ich das tat erkannte ich hartmann schedels ziemlich unverwechselbare schriftzüge und bemerkte bei einem blick auf die münchner digitalisate den typischen signaturzettel auf dem titel das bemerkenswerte familienbuch der nürnberger familie grabner erscheint in der liste von schedels büchern bei stauber https archive org stream dieschedelscheb hartgoog page n mode up die handschriftendatenbank ist denkbar benutzerunfreundlich fürs browsen nicht digitalisierter handschriften verwende ich in unkenntnis eines besseren zugriffs die url von nutzen ist allerdings die volltextsuche die trunkierung mit ermöglicht\n"
     ]
    }
   ],
   "source": [
    "print(z_train[0])\n",
    "print(y_train[0])\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-hot-Kodierung der Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# k-hot-encode labels mit MultiLabelBinarizer\n",
    "label_encoder = MultiLabelBinarizer()\n",
    "encoded_y_train = label_encoder.fit_transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "print(encoded_y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "0 administration publique et développement_d\n",
      "1 anthropologie_t\n",
      "2 arts et humanités_d\n",
      "3 asie_t\n",
      "4 bibliothéconomie_d\n",
      "5 droit_t\n",
      "6 ethnologie_t\n",
      "7 europe_t\n",
      "8 géographie_t\n",
      "9 histoire et archéologie_d\n",
      "10 histoire_t\n",
      "11 information_t\n",
      "12 langage_t\n",
      "13 langue et linguistique_d\n",
      "14 littérature_d\n",
      "15 moyen âge_t\n",
      "16 pensée_t\n",
      "17 pluridisciplinarité_d\n",
      "18 psychisme_t\n",
      "19 psychologie_d\n",
      "20 religions_t\n",
      "21 représentations_t\n",
      "22 sciences de l'information et de la communication_d\n",
      "23 sciences de la santé et de la santé publique_d\n",
      "24 sciences politiques_d\n",
      "25 sociologie et anthropologie_d\n",
      "26 sociologie_t\n",
      "27 travail social et politique sociale_d\n",
      "28 éducation_d\n",
      "29 éducation_t\n",
      "30 épistémologie et méthodes_t\n",
      "31 époque contemporaine_t\n",
      "32 époque moderne_t\n",
      "33 études des sciences_t\n",
      "34 études du politique_t\n"
     ]
    }
   ],
   "source": [
    "print(len(label_encoder.classes_))\n",
    "for i, element in enumerate(label_encoder.classes_):\n",
    "    print(i, element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vektorisierung und Klassifikation der Daten mit scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best params from randomized search\n",
    "text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(2,2), max_df=0.9, min_df=0.01)),\n",
    "                     ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                     ('clf', KNeighborsClassifier(n_neighbors=6, weights='distance')),\n",
    "                   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "start = time.time()\n",
    "text_clf = text_clf.fit(X_train, encoded_y_train)\n",
    "processing_time = (time.time() - start) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predicted = text_clf.predict(X_test)\n",
    "#predicted_proba = text_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': None, 'steps': [('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.9, max_features=None, min_df=0.01,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)), ('tfidf', TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)), ('clf', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
      "           weights='distance'))], 'vect': CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.9, max_features=None, min_df=0.01,\n",
      "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None), 'tfidf': TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True), 'clf': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
      "           weights='distance'), 'vect__analyzer': 'word', 'vect__binary': False, 'vect__decode_error': 'strict', 'vect__dtype': <class 'numpy.int64'>, 'vect__encoding': 'utf-8', 'vect__input': 'content', 'vect__lowercase': True, 'vect__max_df': 0.9, 'vect__max_features': None, 'vect__min_df': 0.01, 'vect__ngram_range': (2, 2), 'vect__preprocessor': None, 'vect__stop_words': None, 'vect__strip_accents': None, 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'vect__tokenizer': None, 'vect__vocabulary': None, 'tfidf__norm': 'l2', 'tfidf__smooth_idf': True, 'tfidf__sublinear_tf': False, 'tfidf__use_idf': True, 'clf__algorithm': 'auto', 'clf__leaf_size': 30, 'clf__metric': 'minkowski', 'clf__metric_params': None, 'clf__n_jobs': 1, 'clf__n_neighbors': 6, 'clf__p': 2, 'clf__weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "clf_params = text_clf.get_params()\n",
    "print(clf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6687134063536588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# precision is a measure of result relevancy\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(encoded_y_test, predicted, average='samples')\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4638039211321119\n"
     ]
    }
   ],
   "source": [
    "# recall is a measure of how many truly relevant results are returned\n",
    "from sklearn.metrics import recall_score\n",
    "recall = recall_score(encoded_y_test, predicted, average='samples')  \n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5214151310224241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# F1 score is a weighted average of the precision and recall\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(encoded_y_test, predicted, average='samples') \n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# write corpus specific stopwords to file \n",
    "\n",
    "stopwords = text_clf.named_steps.vect.stop_words_\n",
    "print(len(stopwords))\n",
    "#print(stopwords)\n",
    "with open('../Preprocessing/filtered_words_reduced_labels.txt',\"w+\", encoding=\"utf8\") as stops:\n",
    "    for element in stopwords:\n",
    "        stops.write(element)\n",
    "        stops.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameteroptimierung mit Rastersuche (RandomizedSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', KNeighborsClassifier())\n",
    "               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter tuning with RandomSearch\n",
    "parameters = {'vect__ngram_range': [(1,1),(1,2),(1,3),(1,4),(2,2),(3,3)], \n",
    "              'vect__max_df' : (0.8, 0.9, 1.0), \n",
    "              'vect__min_df' : (0.0, 0.01, 0.05,),\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__n_neighbors': list(range(1,10,1)),\n",
    "              'clf__weights' : ('distance', 'uniform')\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "clf = Pipeline([#('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfVectorizer()),\n",
    "                ('clf', KNeighborsClassifier()),\n",
    "                ])\n",
    "\n",
    "# parameter tuning with RandomSearch\n",
    "parameters = {'tfidf__ngram_range': [(1,1),(1,2),(1,3),(1,4)], \n",
    "              'tfidf__max_df' : (0.7, 0.8, 0.9, 1.0), \n",
    "              'tfidf__min_df' : (0.0, 0.01, 0.05, 0.1),\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__n_neighbors': list(range(1,10,1)),\n",
    "              'clf__weights' : ('distance', 'uniform')\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    793\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 794\u001b[1;33m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    795\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfeature_idx\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeature_counter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'der'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-547124a823eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mrs_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrs_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrs_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded_y_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mrs_processing_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             train_scores = _score(estimator, X_train, y_train, scorer,\n\u001b[1;32m--> 492\u001b[1;33m                                   is_multimetric)\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \"\"\"\n\u001b[0;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[1;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m         \u001b[0mscore_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents, copy)\u001b[0m\n\u001b[0;32m   1407\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_tfidf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'The tfidf vector is not fitted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m         \u001b[1;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 923\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    924\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hartmann\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    797\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m                         \u001b[0mfeature_counter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 799\u001b[1;33m                 \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    800\u001b[0m                     \u001b[1;31m# Ignore out-of-vocabulary items for fixed_vocab=True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "rs_clf = RandomizedSearchCV(clf, parameters, n_jobs=1, verbose=1, random_state=1, return_train_score=True, cv=3, n_iter=50)\n",
    "start = time.time()\n",
    "rs_clf = rs_clf.fit(X_train, encoded_y_train)\n",
    "rs_processing_time = (time.time() - start) / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6405985154012508\n"
     ]
    }
   ],
   "source": [
    "best_score = rs_clf.best_score_\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vect__ngram_range': (1, 1), 'vect__min_df': 0.0, 'vect__max_df': 0.8, 'tfidf__use_idf': True, 'clf__weights': 'uniform', 'clf__n_neighbors': 1}\n"
     ]
    }
   ],
   "source": [
    "best_params = rs_clf.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict \n",
    "rs_predicted = rs_clf.predict(X_test)\n",
    "#print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7985712245003971\n"
     ]
    }
   ],
   "source": [
    "# precision is a measure of result relevancy\n",
    "from sklearn.metrics import precision_score\n",
    "rs_precision = precision_score(encoded_y_test, rs_predicted, average='samples')\n",
    "print(rs_precision)\n",
    "#0.8579"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7983755945887783\n"
     ]
    }
   ],
   "source": [
    "# recall is a measure of how many truly relevant results are returned\n",
    "from sklearn.metrics import recall_score\n",
    "rs_recall = recall_score(encoded_y_test, rs_predicted, average='samples')  \n",
    "print(rs_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7925753029890477\n"
     ]
    }
   ],
   "source": [
    "# F1 score is a weighted average of the precision and recall\n",
    "from sklearn.metrics import f1_score\n",
    "rs_f1 = f1_score(encoded_y_test, rs_predicted, average='samples') \n",
    "print(rs_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ergebnisse in Dateien speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = '../kNN'\n",
    "if not os.path.exists(output):\n",
    "    os.makedirs(output)\n",
    "    \n",
    "timestamp = time.strftime('%Y-%m-%d_%H.%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTED:\n",
      "('histoire et archéologie_d', 'histoire_t', 'épistémologie et méthodes_t')\n",
      "TRUE:\n",
      "['pluridisciplinarité_d', 'épistémologie et méthodes_t', 'histoire_t', 'histoire et archéologie_d']\n"
     ]
    }
   ],
   "source": [
    "# write real labels and predictions to file\n",
    "\n",
    "inverse_prediction = label_encoder.inverse_transform(rs_predicted)\n",
    "print('PREDICTED:')\n",
    "print(inverse_prediction[0])\n",
    "print('TRUE:')\n",
    "print(y_test[0])\n",
    "\n",
    "with open(output+'/kNN_reduced_labels_predictions_%s.txt' % timestamp,\"w+\", encoding=\"utf8\") as preds:\n",
    "    preds.write(\"Predictions from classification with k-nearest-neighbors (reduced labels):\\n\\n\")\n",
    "    for ident, label, pred in zip(z_test, y_test, inverse_prediction):\n",
    "        label = sorted(label)\n",
    "        pred = sorted(pred)\n",
    "        preds.write(ident)\n",
    "        preds.write('\\n')\n",
    "        preds.write('TRUE: ')\n",
    "        for element in label:\n",
    "            preds.write('%s, ' % element)\n",
    "        preds.write('\\n')\n",
    "        preds.write('PRED: ')\n",
    "        for element in pred:\n",
    "            preds.write('%s, ' % element)\n",
    "        preds.write('\\n')\n",
    "        preds.write('\\n*********************\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write parameters and scores to file\n",
    "\n",
    "with open(output+'/kNN_reduced_labels_params_%s.txt' % timestamp,\"w+\", encoding=\"utf8\") as params:\n",
    "    params.write(\"Parameters for classification with k-nearest-neighbors from randomized search (reduced labels):\")\n",
    "    params.write(\"\\nprocessing_time: %s\" % rs_processing_time)\n",
    "    for key, value in best_params.items():\n",
    "        params.write(\"\\n%s: %s\" % (key, value))\n",
    "    params.write(\"\\nbest_score: %s\" % best_score)\n",
    "    params.write(\"\\nprecision: %s\" % rs_precision)\n",
    "    params.write(\"\\nrecall: %s\" % rs_recall)\n",
    "    params.write(\"\\nf1-score: %s\" % rs_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0        3.557203      0.092697         5.869590        0.052982   \n",
      "1       82.193439     21.199769        18.953067        7.823778   \n",
      "2       25.521886      9.640995        13.179605        4.641404   \n",
      "3        3.394821      0.173413         5.469966        0.147285   \n",
      "4       32.706812      3.828990        12.022873        5.707268   \n",
      "5       55.633518     15.551100         8.519456        0.251476   \n",
      "6        3.315675      0.034034         5.075876        0.042897   \n",
      "7       13.086049      0.210817         7.391932        0.068449   \n",
      "8       29.587317      0.899688         8.617346        0.293419   \n",
      "9       52.819775      4.772485        10.803697        1.691523   \n",
      "10      64.224142     13.353591        18.167801        8.400733   \n",
      "11      90.067466     30.682572        15.291221        5.749664   \n",
      "12      13.986063      0.204836         8.659735        0.147837   \n",
      "13       3.481476      0.060530         5.613819        0.177023   \n",
      "14      40.460809     26.464493        18.799415        9.920327   \n",
      "15     188.313051     73.032014        34.819708       12.755932   \n",
      "16      23.144895      8.744787        31.477808       11.532443   \n",
      "17     167.164468     51.358888        23.516993        1.983250   \n",
      "18      48.334702      2.236761        11.026704        0.212826   \n",
      "19     152.700425    151.431671        18.707330        8.035032   \n",
      "20      52.940427     15.709775        31.389856       15.332114   \n",
      "21     315.319115    119.023326        57.670219       22.170379   \n",
      "22      24.853845      9.469963        36.350460       13.432038   \n",
      "23      44.269510     15.422233        25.247951       11.145606   \n",
      "24       4.088375      0.062410         6.281368        0.155206   \n",
      "25      15.217124      0.463002         7.485995        0.197813   \n",
      "26       3.917039      0.028845         5.914889        0.083442   \n",
      "27       4.062173      0.106304         6.109514        0.085785   \n",
      "28      14.736077      0.226744         7.888221        0.089253   \n",
      "29      33.164683      0.391765         8.818056        0.106491   \n",
      "30      32.536157      0.455866         9.755993        0.206582   \n",
      "31       3.919490      0.136717         5.723072        0.050248   \n",
      "32      32.624957      0.272314         9.413299        0.053538   \n",
      "33      33.108986      0.135659         8.856640        0.121781   \n",
      "34      15.863249      0.257360         9.531115        0.215010   \n",
      "35      52.764482      0.769770        10.332522        0.090683   \n",
      "36      14.837476      0.407787         7.743067        0.065964   \n",
      "37      52.853492      0.598869        10.860165        0.184237   \n",
      "38      32.862396      0.520521         9.885014        0.176818   \n",
      "39       4.130109      0.064423         7.081621        0.113103   \n",
      "40      52.713274      0.524145        10.368222        0.122393   \n",
      "41       3.917621      0.010661         7.062012        0.144749   \n",
      "42       4.199191      0.169096         6.703752        0.126378   \n",
      "43      15.073119      0.044847         7.840293        0.133099   \n",
      "44      32.661006      0.213982         8.361243        0.047383   \n",
      "45       3.847415      0.098520         5.663498        0.046792   \n",
      "46      60.449244      0.555861        14.957868        0.165660   \n",
      "47      53.108740      0.496297        10.815168        0.033520   \n",
      "48      35.021399      0.527622        12.408713        0.259078   \n",
      "49      32.768193      0.512422         9.410404        0.044368   \n",
      "\n",
      "   param_vect__ngram_range param_vect__min_df param_vect__max_df  \\\n",
      "0                   (1, 1)               0.05                0.9   \n",
      "1                   (1, 4)                  0                0.9   \n",
      "2                   (1, 2)               0.01                0.8   \n",
      "3                   (1, 1)               0.05                  1   \n",
      "4                   (1, 3)                0.1                  1   \n",
      "5                   (1, 4)                0.1                0.9   \n",
      "6                   (1, 1)               0.05                0.7   \n",
      "7                   (1, 2)               0.05                  1   \n",
      "8                   (1, 3)               0.05                  1   \n",
      "9                   (1, 4)                0.1                0.7   \n",
      "10                  (1, 4)                  0                0.9   \n",
      "11                  (1, 4)               0.05                0.9   \n",
      "12                  (1, 2)                  0                0.8   \n",
      "13                  (1, 1)                0.1                0.9   \n",
      "14                  (1, 2)                0.1                0.8   \n",
      "15                  (1, 4)               0.01                0.7   \n",
      "16                  (1, 1)                  0                0.8   \n",
      "17                  (1, 4)               0.05                0.8   \n",
      "18                  (1, 4)                  0                0.7   \n",
      "19                  (1, 4)                0.1                0.9   \n",
      "20                  (1, 2)               0.05                0.8   \n",
      "21                  (1, 4)                0.1                0.9   \n",
      "22                  (1, 1)               0.05                0.9   \n",
      "23                  (1, 2)                  0                0.7   \n",
      "24                  (1, 1)               0.01                0.7   \n",
      "25                  (1, 2)               0.05                0.7   \n",
      "26                  (1, 1)                0.1                0.8   \n",
      "27                  (1, 1)                0.1                0.9   \n",
      "28                  (1, 2)                0.1                  1   \n",
      "29                  (1, 3)               0.01                0.7   \n",
      "30                  (1, 3)               0.01                0.8   \n",
      "31                  (1, 1)               0.05                0.9   \n",
      "32                  (1, 3)               0.05                0.9   \n",
      "33                  (1, 3)                0.1                0.9   \n",
      "34                  (1, 2)                  0                0.9   \n",
      "35                  (1, 4)               0.05                0.8   \n",
      "36                  (1, 2)                0.1                  1   \n",
      "37                  (1, 4)               0.05                0.8   \n",
      "38                  (1, 3)               0.01                0.9   \n",
      "39                  (1, 1)                  0                0.9   \n",
      "40                  (1, 4)               0.05                0.8   \n",
      "41                  (1, 1)                  0                0.9   \n",
      "42                  (1, 1)                  0                0.9   \n",
      "43                  (1, 2)               0.05                0.9   \n",
      "44                  (1, 3)                0.1                0.7   \n",
      "45                  (1, 1)               0.05                0.7   \n",
      "46                  (1, 4)                  0                0.9   \n",
      "47                  (1, 4)               0.05                  1   \n",
      "48                  (1, 3)                  0                  1   \n",
      "49                  (1, 3)               0.01                0.8   \n",
      "\n",
      "   param_tfidf__use_idf param_clf__weights param_clf__n_neighbors  \\\n",
      "0                 False           distance                      5   \n",
      "1                  True           distance                      6   \n",
      "2                 False            uniform                      5   \n",
      "3                  True           distance                      1   \n",
      "4                  True           distance                      5   \n",
      "5                 False           distance                      1   \n",
      "6                 False           distance                      9   \n",
      "7                  True           distance                      4   \n",
      "8                  True           distance                      5   \n",
      "9                 False           distance                      5   \n",
      "10                False           distance                      5   \n",
      "11                False           distance                      5   \n",
      "12                False            uniform                      5   \n",
      "13                 True            uniform                      7   \n",
      "14                 True           distance                      2   \n",
      "15                False           distance                      3   \n",
      "16                 True            uniform                      7   \n",
      "17                False            uniform                      7   \n",
      "18                False            uniform                      1   \n",
      "19                False           distance                      2   \n",
      "20                False            uniform                      7   \n",
      "21                 True           distance                      1   \n",
      "22                False            uniform                      4   \n",
      "23                False            uniform                      9   \n",
      "24                False           distance                      7   \n",
      "25                False           distance                      5   \n",
      "26                False           distance                      9   \n",
      "27                False           distance                      8   \n",
      "28                False           distance                      4   \n",
      "29                 True           distance                      1   \n",
      "30                 True           distance                      7   \n",
      "31                 True           distance                      1   \n",
      "32                 True           distance                      6   \n",
      "33                 True            uniform                      8   \n",
      "34                False            uniform                      3   \n",
      "35                False           distance                      5   \n",
      "36                False           distance                      9   \n",
      "37                False            uniform                      4   \n",
      "38                 True           distance                      6   \n",
      "39                False           distance                      9   \n",
      "40                 True           distance                      9   \n",
      "41                False            uniform                      7   \n",
      "42                False            uniform                      3   \n",
      "43                False           distance                      7   \n",
      "44                 True            uniform                      5   \n",
      "45                False           distance                      8   \n",
      "46                 True           distance                      5   \n",
      "47                False            uniform                      9   \n",
      "48                False            uniform                      5   \n",
      "49                False           distance                      3   \n",
      "\n",
      "         ...        split1_test_score  split2_test_score  mean_test_score  \\\n",
      "0        ...                 0.302472           0.284587         0.289906   \n",
      "1        ...                 0.620200           0.605120         0.615407   \n",
      "2        ...                 0.248115           0.239523         0.239465   \n",
      "3        ...                 0.377170           0.360687         0.367935   \n",
      "4        ...                 0.306505           0.286867         0.291542   \n",
      "5        ...                 0.330703           0.322988         0.322988   \n",
      "6        ...                 0.292127           0.278099         0.282717   \n",
      "7        ...                 0.311766           0.293705         0.299141   \n",
      "8        ...                 0.274242           0.257408         0.264364   \n",
      "9        ...                 0.299667           0.295459         0.293062   \n",
      "10       ...                 0.301596           0.253726         0.276580   \n",
      "11       ...                 0.298439           0.278976         0.285522   \n",
      "12       ...                 0.362792           0.322637         0.337366   \n",
      "13       ...                 0.304226           0.295985         0.295575   \n",
      "14       ...                 0.375066           0.358233         0.363318   \n",
      "15       ...                 0.242679           0.239172         0.237068   \n",
      "16       ...                 0.581624           0.568473         0.574376   \n",
      "17       ...                 0.284061           0.266702         0.274183   \n",
      "18       ...                 0.487813           0.426968         0.450582   \n",
      "19       ...                 0.330528           0.322287         0.322403   \n",
      "20       ...                 0.284587           0.268806         0.275060   \n",
      "21       ...                 0.373663           0.355778         0.361330   \n",
      "22       ...                 0.254252           0.237945         0.243907   \n",
      "23       ...                 0.399088           0.356304         0.373838   \n",
      "24       ...                 0.297037           0.297387         0.301187   \n",
      "25       ...                 0.302122           0.291250         0.292536   \n",
      "26       ...                 0.276170           0.274066         0.269975   \n",
      "27       ...                 0.275294           0.271261         0.269273   \n",
      "28       ...                 0.279853           0.269157         0.270442   \n",
      "29       ...                 0.163949           0.166228         0.164533   \n",
      "30       ...                 0.243731           0.251447         0.281314   \n",
      "31       ...                 0.364019           0.345958         0.356888   \n",
      "32       ...                 0.261091           0.240575         0.251330   \n",
      "33       ...                 0.265825           0.257934         0.255421   \n",
      "34       ...                 0.354901           0.312467         0.331112   \n",
      "35       ...                 0.302122           0.288445         0.290900   \n",
      "36       ...                 0.245485           0.240224         0.239582   \n",
      "37       ...                 0.259162           0.244257         0.247940   \n",
      "38       ...                 0.117307           0.118709         0.121047   \n",
      "39       ...                 0.331931           0.308610         0.315565   \n",
      "40       ...                 0.217079           0.204278         0.212169   \n",
      "41       ...                 0.344380           0.318429         0.327722   \n",
      "42       ...                 0.378923           0.359811         0.367058   \n",
      "43       ...                 0.282308           0.263546         0.272079   \n",
      "44       ...                 0.308434           0.288269         0.295225   \n",
      "45       ...                 0.303875           0.297913         0.298264   \n",
      "46       ...                 0.615466           0.597054         0.606932   \n",
      "47       ...                 0.253375           0.240750         0.245193   \n",
      "48       ...                 0.219183           0.185867         0.198258   \n",
      "49       ...                 0.284236           0.271611         0.272547   \n",
      "\n",
      "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0         0.008921               26            0.996055            0.994214   \n",
      "1         0.007280                1            0.997720            0.996142   \n",
      "2         0.007087               45            0.299141            0.359109   \n",
      "3         0.006874                6            0.997808            0.996493   \n",
      "4         0.010825               24            0.995529            0.992898   \n",
      "5         0.006299               14            0.996493            0.994915   \n",
      "6         0.006654               28            0.995003            0.992898   \n",
      "7         0.008956               18            0.996405            0.994477   \n",
      "8         0.007176               38            0.996405            0.994389   \n",
      "9         0.006593               22            0.992898            0.990444   \n",
      "10        0.019602               30            0.997370            0.995704   \n",
      "11        0.009134               27            0.996318            0.994214   \n",
      "12        0.018054               11            0.436525            0.454761   \n",
      "13        0.007236               20            0.355953            0.362704   \n",
      "14        0.008332                8            0.994214            0.991671   \n",
      "15        0.005640               46            0.997019            0.995529   \n",
      "16        0.005452                3            0.646414            0.651061   \n",
      "17        0.007287               32            0.335437            0.339470   \n",
      "18        0.026641                4            0.998510            0.997633   \n",
      "19        0.006586               15            0.994389            0.991934   \n",
      "20        0.006846               31            0.336314            0.339733   \n",
      "21        0.008735                9            0.996493            0.994915   \n",
      "22        0.007344               43            0.326056            0.321673   \n",
      "23        0.018299                5            0.432492            0.443451   \n",
      "24        0.005623               17            0.997019            0.995441   \n",
      "25        0.007358               23            0.995090            0.993249   \n",
      "26        0.007325               36            0.994126            0.991934   \n",
      "27        0.005897               37            0.994301            0.992109   \n",
      "28        0.007216               35            0.995529            0.993074   \n",
      "29        0.001218               49            0.998334            0.997370   \n",
      "30        0.047798               29            0.997019            0.995266   \n",
      "31        0.007847               10            0.997545            0.996230   \n",
      "32        0.008405               40            0.996142            0.993951   \n",
      "33        0.009685               39            0.294143            0.294932   \n",
      "34        0.017701               12            0.504822            0.514641   \n",
      "35        0.008343               25            0.995967            0.994126   \n",
      "36        0.005103               44            0.995529            0.993074   \n",
      "37        0.008090               41            0.324478            0.325530   \n",
      "38        0.004336               50            0.997019            0.995266   \n",
      "39        0.011616               16            0.997370            0.995704   \n",
      "40        0.005635               47            0.996142            0.993863   \n",
      "41        0.011805               13            0.396721            0.405313   \n",
      "42        0.008458                7            0.538225            0.545853   \n",
      "43        0.007753               34            0.996142            0.994038   \n",
      "44        0.009345               21            0.387603            0.391811   \n",
      "45        0.004445               19            0.995090            0.992898   \n",
      "46        0.007576                2            0.997720            0.996142   \n",
      "47        0.005793               42            0.284499            0.288094   \n",
      "48        0.014880               48            0.281255            0.305541   \n",
      "49        0.009187               33            0.997194            0.995529   \n",
      "\n",
      "    split2_train_score  mean_train_score  std_train_score  \n",
      "0             0.994564          0.994944         0.000798  \n",
      "1             0.996493          0.996785         0.000677  \n",
      "2             0.312204          0.323485         0.025749  \n",
      "3             0.996581          0.996961         0.000600  \n",
      "4             0.993688          0.994038         0.001102  \n",
      "5             0.994740          0.995383         0.000789  \n",
      "6             0.993688          0.993863         0.000868  \n",
      "7             0.995090          0.995324         0.000805  \n",
      "8             0.995178          0.995324         0.000830  \n",
      "9             0.991233          0.991525         0.001023  \n",
      "10            0.996318          0.996464         0.000688  \n",
      "11            0.994740          0.995090         0.000894  \n",
      "12            0.415921          0.435736         0.015866  \n",
      "13            0.360074          0.359577         0.002778  \n",
      "14            0.991583          0.992489         0.001220  \n",
      "15            0.995704          0.996084         0.000665  \n",
      "16            0.643346          0.646940         0.003172  \n",
      "17            0.332983          0.335964         0.002675  \n",
      "18            0.997633          0.997925         0.000413  \n",
      "19            0.991934          0.992752         0.001157  \n",
      "20            0.334824          0.336957         0.002055  \n",
      "21            0.994740          0.995383         0.000789  \n",
      "22            0.317815          0.321848         0.003367  \n",
      "23            0.410924          0.428956         0.013512  \n",
      "24            0.995792          0.996084         0.000677  \n",
      "25            0.994038          0.994126         0.000754  \n",
      "26            0.992109          0.992723         0.000994  \n",
      "27            0.992635          0.993015         0.000934  \n",
      "28            0.993775          0.994126         0.001032  \n",
      "29            0.997370          0.997691         0.000455  \n",
      "30            0.995704          0.995996         0.000745  \n",
      "31            0.996230          0.996668         0.000620  \n",
      "32            0.994564          0.994886         0.000923  \n",
      "33            0.290724          0.293267         0.001826  \n",
      "34            0.482641          0.500701         0.013385  \n",
      "35            0.994740          0.994944         0.000765  \n",
      "36            0.993688          0.994097         0.001043  \n",
      "37            0.320182          0.323397         0.002313  \n",
      "38            0.995704          0.995996         0.000745  \n",
      "39            0.996142          0.996405         0.000705  \n",
      "40            0.994564          0.994857         0.000953  \n",
      "41            0.387954          0.396663         0.007087  \n",
      "42            0.534456          0.539511         0.004741  \n",
      "43            0.994827          0.995003         0.000868  \n",
      "44            0.388567          0.389327         0.001800  \n",
      "45            0.993688          0.993892         0.000906  \n",
      "46            0.996318          0.996727         0.000706  \n",
      "47            0.284236          0.285610         0.001760  \n",
      "48            0.262230          0.283009         0.017725  \n",
      "49            0.995529          0.996084         0.000785  \n",
      "\n",
      "[50 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "results = rs_clf.cv_results_\n",
    "df = pd.DataFrame(data=results)\n",
    "print(df)\n",
    "df.to_csv(output+'/kNN_reduced_labels_rs_results_%s.csv' % timestamp, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
